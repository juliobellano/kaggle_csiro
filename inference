{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c30c57f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-22T07:22:52.095969Z",
     "iopub.status.busy": "2025-12-22T07:22:52.095739Z",
     "iopub.status.idle": "2025-12-22T07:22:52.099524Z",
     "shell.execute_reply": "2025-12-22T07:22:52.098967Z"
    },
    "papermill": {
     "duration": 0.008048,
     "end_time": "2025-12-22T07:22:52.100875",
     "exception": false,
     "start_time": "2025-12-22T07:22:52.092827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# # For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# # Input data files are available in the read-only \"../input/\" directory\n",
    "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input/csiro-biomass/test'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40086798",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-22T07:22:52.104670Z",
     "iopub.status.busy": "2025-12-22T07:22:52.104248Z",
     "iopub.status.idle": "2025-12-22T07:23:00.636902Z",
     "shell.execute_reply": "2025-12-22T07:23:00.636154Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 8.536653,
     "end_time": "2025-12-22T07:23:00.638953",
     "exception": false,
     "start_time": "2025-12-22T07:22:52.102300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\r\n",
      "Requirement already satisfied: torch==2.8.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2025.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.8.0->torchvision) (3.4.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.8.0->torchvision) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.8.0->torchvision) (3.0.3)\r\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c43d3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T07:23:00.644205Z",
     "iopub.status.busy": "2025-12-22T07:23:00.643961Z",
     "iopub.status.idle": "2025-12-22T07:23:43.870253Z",
     "shell.execute_reply": "2025-12-22T07:23:43.869326Z"
    },
    "papermill": {
     "duration": 43.231203,
     "end_time": "2025-12-22T07:23:43.872046",
     "exception": false,
     "start_time": "2025-12-22T07:23:00.640843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building backbone: vit_large_patch14_dinov2\n",
      "Loading weights from: /kaggle/input/dinov2-backbone/dinov2_vitl14.pth\n",
      "Loading trained checkpoint: /kaggle/input/dinov2-1/experiments/dinov2_tiled/fold_2/best_model.pth\n",
      "Note: Ignored unexpected keys: ['backbone.mask_token']\n",
      "✓ Trained model loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1/1 [00:03<00:00,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Submission saved to /kaggle/working/submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "class InferenceConfig:\n",
    "    \"\"\"Inference configuration.\"\"\"\n",
    "    # Paths\n",
    "    DATA_DIR = None  # Auto-detected\n",
    "    CHECKPOINT_PATH = '/kaggle/input/dinov2-1/experiments/dinov2_tiled/fold_2/best_model.pth'\n",
    "    OUTPUT_PATH = '/kaggle/working/submission.csv'\n",
    "    \n",
    "    # Backbone settings\n",
    "    USE_OFFLINE_BACKBONE = True\n",
    "    OFFLINE_BACKBONE_PATH = '/kaggle/input/dinov2-backbone/dinov2_vitl14.pth'\n",
    "    # Use timm name: 'vit_large_patch14_dinov2' = dinov2_vitl14\n",
    "    BACKBONE = 'vit_large_patch14_dinov2' \n",
    "    \n",
    "    # Model settings\n",
    "    USE_GLOBAL_STREAM = True\n",
    "    TILE_SIZE = 518\n",
    "    MLP_HIDDEN_DIMS = [1024, 512]\n",
    "    DROPOUT = 0.3\n",
    "    \n",
    "    # Inference settings\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_WORKERS = 4\n",
    "    USE_TTA = False\n",
    "    APPLY_CONSTRAINT = True\n",
    "    CONSTRAINT_BLEND = 0.3\n",
    "\n",
    "# =============================================================================\n",
    "# DATA TRANSFORMS & DATASET\n",
    "# =============================================================================\n",
    "\n",
    "class TileTransform:\n",
    "    def __init__(self, tile_size=518, include_global=True):\n",
    "        self.tile_size = tile_size\n",
    "        self.include_global = include_global\n",
    "        self.normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.resize = T.Resize((tile_size, tile_size), interpolation=T.InterpolationMode.BICUBIC, antialias=True)\n",
    "    \n",
    "    def _crop_tile(self, image, tile_idx):\n",
    "        w, h = image.size\n",
    "        hw, hh = w // 2, h // 2\n",
    "        pos = {0: (0, 0, hw, hh), 1: (hw, 0, w, hh), 2: (0, hh, hw, h), 3: (hw, hh, w, h)}\n",
    "        return image.crop(pos[tile_idx])\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        tiles = []\n",
    "        for i in range(4):\n",
    "            tile = self.resize(self._crop_tile(image, i))\n",
    "            tiles.append(self.normalize(T.ToTensor()(tile)))\n",
    "        if self.include_global:\n",
    "            tiles.append(self.normalize(T.ToTensor()(self.resize(image))))\n",
    "        return torch.stack(tiles, dim=0)\n",
    "\n",
    "class PastureTestDataset(Dataset):\n",
    "    def __init__(self, df, data_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self): return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.data_dir / row['image_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        tiles = self.transform(image) if self.transform else torch.zeros(5, 3, 518, 518)\n",
    "        return tiles, row['image_id']\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL ARCHITECTURE (Fixed for timm)\n",
    "# =============================================================================\n",
    "\n",
    "class TiledDinoModel(nn.Module):\n",
    "    def __init__(self, backbone_name, num_tiles=5, mlp_hidden_dims=[1024, 512], \n",
    "                 dropout=0.3, freeze_backbone=True, offline_backbone_path=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        print(f\"Building backbone: {backbone_name}\")\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=False, num_classes=0)\n",
    "        \n",
    "        if offline_backbone_path and Path(offline_backbone_path).exists():\n",
    "            print(f\"Loading weights from: {offline_backbone_path}\")\n",
    "            sd = torch.load(offline_backbone_path, map_location='cpu', weights_only=True)\n",
    "            self.backbone.load_state_dict(sd, strict=False)\n",
    "        \n",
    "        self.feature_dim = self.backbone.num_features\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters(): p.requires_grad = False\n",
    "            \n",
    "        layers = []\n",
    "        prev_dim = num_tiles * self.feature_dim\n",
    "        for h in mlp_hidden_dims:\n",
    "            layers.extend([nn.Linear(prev_dim, h), nn.ReLU(inplace=True), nn.Dropout(dropout)])\n",
    "            prev_dim = h\n",
    "        layers.append(nn.Linear(prev_dim, 5))\n",
    "        self.head = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, tiles):\n",
    "        # tiles shape: (B, N, C, H, W)\n",
    "        B, N, C, H, W = tiles.shape\n",
    "        \n",
    "        # 1. Flatten for backbone\n",
    "        flat = tiles.view(B * N, C, H, W)\n",
    "        \n",
    "        # 2. Extract features\n",
    "        features = self.backbone(flat) # Expected shape: (B*N, Dim)\n",
    "        \n",
    "        # 3. FIX: Ensure tensor is contiguous before changing shape\n",
    "        # We use .reshape() which is safer than .view() here\n",
    "        features = features.reshape(B, N * self.feature_dim) \n",
    "        \n",
    "        # 4. Pass through MLP head\n",
    "        return self.head(features)\n",
    "\n",
    "# =============================================================================\n",
    "# CORE FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_model(checkpoint_path, config, device):\n",
    "    num_tiles = 5 if config.USE_GLOBAL_STREAM else 4\n",
    "    model = TiledDinoModel(\n",
    "        backbone_name=config.BACKBONE,\n",
    "        num_tiles=num_tiles,\n",
    "        mlp_hidden_dims=config.MLP_HIDDEN_DIMS,\n",
    "        dropout=config.DROPOUT,\n",
    "        offline_backbone_path=config.OFFLINE_BACKBONE_PATH if config.USE_OFFLINE_BACKBONE else None\n",
    "    )\n",
    "    \n",
    "    print(f\"Loading trained checkpoint: {checkpoint_path}\")\n",
    "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # 1. Extract the state dict\n",
    "    state_dict = ckpt['model_state_dict'] if 'model_state_dict' in ckpt else ckpt\n",
    "    \n",
    "    # 2. Clean up keys (remove 'module.' from DataParallel if it exists)\n",
    "    new_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "    \n",
    "    # 3. CRITICAL: Use strict=False here too\n",
    "    # This allows the model to ignore 'backbone.mask_token' since timm doesn't use it\n",
    "    missing_keys, unexpected_keys = model.load_state_dict(new_state_dict, strict=False)\n",
    "    \n",
    "    if len(unexpected_keys) > 0:\n",
    "        print(f\"Note: Ignored unexpected keys: {unexpected_keys}\")\n",
    "    \n",
    "    model.to(device).eval()\n",
    "    print(\"✓ Trained model loaded successfully!\")\n",
    "    return model\n",
    "\n",
    "def apply_constraint(preds, blend=0.3):\n",
    "    # green, dead, clover, total\n",
    "    component_sum = preds[:, 0] + preds[:, 1] + preds[:, 2]\n",
    "    preds[:, 4] = (1 - blend) * preds[:, 4] + blend * component_sum\n",
    "    return np.maximum(preds, 0)\n",
    "\n",
    "def main():\n",
    "    config = InferenceConfig()\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Path detection\n",
    "    if config.DATA_DIR is None:\n",
    "        for d, _, f in os.walk('/kaggle/input'):\n",
    "            if 'test.csv' in f:\n",
    "                config.DATA_DIR = d\n",
    "                break\n",
    "    \n",
    "    test_df_raw = pd.read_csv(Path(config.DATA_DIR) / 'test.csv')\n",
    "    test_df_raw['image_id'] = test_df_raw['sample_id'].str.split('__').str[0]\n",
    "    unique_images = test_df_raw.groupby('image_id').first().reset_index()[['image_id', 'image_path']]\n",
    "    \n",
    "    dataset = PastureTestDataset(unique_images, config.DATA_DIR, TileTransform(config.TILE_SIZE, config.USE_GLOBAL_STREAM))\n",
    "    loader = DataLoader(dataset, batch_size=config.BATCH_SIZE, num_workers=config.NUM_WORKERS, pin_memory=True)\n",
    "    \n",
    "    model = load_model(config.CHECKPOINT_PATH, config, device)\n",
    "    \n",
    "    all_preds, all_ids = [], []\n",
    "    with torch.no_grad():\n",
    "        for tiles, img_ids in tqdm(loader, desc=\"Predicting\"):\n",
    "            out = model(tiles.to(device))\n",
    "            all_preds.append(out.cpu().numpy())\n",
    "            all_ids.extend(img_ids)\n",
    "    \n",
    "    preds = np.vstack(all_preds)\n",
    "    if config.APPLY_CONSTRAINT: preds = apply_constraint(preds, config.CONSTRAINT_BLEND)\n",
    "    \n",
    "    # Build Submission\n",
    "    target_names = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "    sub_rows = []\n",
    "    for i, img_id in enumerate(all_ids):\n",
    "        for j, t_name in enumerate(target_names):\n",
    "            sub_rows.append({'sample_id': f\"{img_id}__{t_name}\", 'target': preds[i, j]})\n",
    "    \n",
    "    pd.DataFrame(sub_rows).to_csv(config.OUTPUT_PATH, index=False)\n",
    "    print(f\"Done! Submission saved to {config.OUTPUT_PATH}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d9e5799",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T07:23:43.877886Z",
     "iopub.status.busy": "2025-12-22T07:23:43.877639Z",
     "iopub.status.idle": "2025-12-22T07:23:44.053641Z",
     "shell.execute_reply": "2025-12-22T07:23:44.052774Z"
    },
    "papermill": {
     "duration": 0.180919,
     "end_time": "2025-12-22T07:23:44.055303",
     "exception": false,
     "start_time": "2025-12-22T07:23:43.874384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dinov2/pytorch/large/1:\r\n",
      "config.json  preprocessor_config.json  pytorch_model.bin  README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls -R /kaggle/input/dinov2/pytorch/large/1"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "sourceId": 287733923,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 287736779,
     "sourceType": "kernelVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 986,
     "modelInstanceId": 3327,
     "sourceId": 4535,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 58.782111,
   "end_time": "2025-12-22T07:23:47.378153",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-22T07:22:48.596042",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
