{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"dockerImageVersionId":31239,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-22T00:04:00.270251Z","iopub.execute_input":"2025-12-22T00:04:00.270542Z","iopub.status.idle":"2025-12-22T00:04:00.276857Z","shell.execute_reply.started":"2025-12-22T00:04:00.270521Z","shell.execute_reply":"2025-12-22T00:04:00.275798Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\"\"\"\nDINOv2 Inference - Generate Competition Submission\n\"\"\"\n\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nimport torchvision.transforms as T\n\n# =============================================================================\n# COPY MODEL AND TRANSFORM CLASSES (from your training script)\n# =============================================================================\n\nclass TileTransform:\n    \"\"\"Split image into 2x2 tiles + optional global.\"\"\"\n    \n    def __init__(self, tile_size=518, include_global=True):\n        self.tile_size = tile_size\n        self.include_global = include_global\n        \n        self.normalize = T.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225]\n        )\n        self.resize = T.Resize((tile_size, tile_size), \n                              interpolation=T.InterpolationMode.BICUBIC, \n                              antialias=True)\n    \n    def _crop_tile(self, image, tile_idx):\n        w, h = image.size\n        half_w, half_h = w // 2, h // 2\n        positions = {\n            0: (0, 0, half_w, half_h),\n            1: (half_w, 0, w, half_h),\n            2: (0, half_h, half_w, h),\n            3: (half_w, half_h, w, h),\n        }\n        return image.crop(positions[tile_idx])\n    \n    def __call__(self, image):\n        tiles = []\n        for i in range(4):\n            tile = self._crop_tile(image, i)\n            tile = self.resize(tile)\n            tile = T.ToTensor()(tile)\n            tile = self.normalize(tile)\n            tiles.append(tile)\n        \n        if self.include_global:\n            global_img = self.resize(image)\n            global_img = T.ToTensor()(global_img)\n            global_img = self.normalize(global_img)\n            tiles.append(global_img)\n        \n        return torch.stack(tiles, dim=0)\n\n\nclass TiledDinoModel(nn.Module):\n    \"\"\"DINOv2 with tiled input processing.\"\"\"\n    \n    def __init__(self, backbone_name='dinov2_vitl14', num_tiles=5, \n                 mlp_hidden_dims=[1024, 512], dropout=0.3, freeze_backbone=True):\n        super().__init__()\n        \n        self.backbone = torch.hub.load('facebookresearch/dinov2', \n                                      backbone_name, pretrained=True)\n        self.feature_dim = self.backbone.embed_dim\n        self.num_tiles = num_tiles\n        \n        if freeze_backbone:\n            for param in self.backbone.parameters():\n                param.requires_grad = False\n        \n        # MLP head\n        layers = []\n        prev_dim = num_tiles * self.feature_dim\n        for hidden_dim in mlp_hidden_dims:\n            layers.extend([\n                nn.Linear(prev_dim, hidden_dim),\n                nn.ReLU(inplace=True),\n                nn.Dropout(p=dropout),\n            ])\n            prev_dim = hidden_dim\n        layers.append(nn.Linear(prev_dim, 5))\n        self.head = nn.Sequential(*layers)\n    \n    def forward(self, tiles):\n        batch_size, num_tiles, channels, height, width = tiles.shape\n        tiles_flat = tiles.reshape(batch_size * num_tiles, channels, height, width)\n        \n        with torch.set_grad_enabled(self.training):\n            features = self.backbone(tiles_flat)\n        \n        features = features.contiguous().view(batch_size, num_tiles * self.feature_dim)\n        return self.head(features)\n\n\nclass TestDataset(Dataset):\n    \"\"\"Test dataset for inference.\"\"\"\n    \n    def __init__(self, df, data_dir, transform):\n        self.df = df.reset_index(drop=True)\n        self.data_dir = Path(data_dir)\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = self.data_dir / row['image_path']\n        image = Image.open(img_path).convert('RGB')\n        tiles = self.transform(image)\n        return tiles, row['image_id']\n\n\n# =============================================================================\n# LOAD TEST DATA\n# =============================================================================\n\ndef load_test_data(data_dir):\n    \"\"\"Load test data.\"\"\"\n    df_long = pd.read_csv(Path(data_dir) / 'test.csv')\n    df_long['image_id'] = df_long['sample_id'].str.split('__').str[0]\n    df_test = df_long[['image_id', 'image_path']].drop_duplicates()\n    return df_test.reset_index(drop=True)\n\n\n# =============================================================================\n# INFERENCE FUNCTION\n# =============================================================================\n\ndef run_inference(model, dataloader, device):\n    \"\"\"Run inference and return predictions.\"\"\"\n    model.eval()\n    all_predictions = []\n    all_image_ids = []\n    \n    with torch.no_grad():\n        for tiles, image_ids in tqdm(dataloader, desc='Inference'):\n            tiles = tiles.to(device)\n            outputs = model(tiles)\n            \n            all_predictions.append(outputs.cpu().numpy())\n            all_image_ids.extend(image_ids)\n    \n    predictions = np.vstack(all_predictions)\n    return predictions, all_image_ids\n\n\ndef create_submission(predictions, image_ids, output_path):\n    \"\"\"Create submission CSV in competition format.\"\"\"\n    target_names = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n    \n    rows = []\n    for i, image_id in enumerate(image_ids):\n        for j, target_name in enumerate(target_names):\n            sample_id = f\"{image_id}__{target_name}\"\n            target_value = predictions[i, j]\n            rows.append({\n                'sample_id': sample_id,\n                'target': target_value\n            })\n    \n    submission_df = pd.DataFrame(rows)\n    submission_df.to_csv(output_path, index=False)\n    return submission_df\n\n\n# =============================================================================\n# MAIN INFERENCE\n# =============================================================================\n\ndef main():\n    # Configuration\n    DATA_DIR = '/kaggle/input/csiro-biomass'  # Adjust to your data location\n    MODEL_PATH = '/kaggle/input/your-model-dataset/best_model.pth'  # Your trained model\n    OUTPUT_PATH = '/kaggle/working/submission.csv'\n    \n    BATCH_SIZE = 8\n    NUM_WORKERS = 2\n    TILE_SIZE = 518\n    USE_GLOBAL_STREAM = True\n    \n    # Setup device\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Device: {device}\")\n    \n    # Load checkpoint\n    print(f\"\\nðŸ“¥ Loading model from {MODEL_PATH}...\")\n    checkpoint = torch.load(MODEL_PATH, map_location=device)\n    \n    # Get model config from checkpoint\n    model_config = checkpoint.get('model_config', {})\n    backbone_name = model_config.get('backbone_name', 'dinov2_vitl14')\n    num_tiles = model_config.get('num_tiles', 5)\n    mlp_hidden_dims = model_config.get('mlp_hidden_dims', [1024, 512])\n    dropout = model_config.get('dropout', 0.3)\n    \n    print(f\"Model config: {backbone_name}, {num_tiles} tiles\")\n    \n    # Create model\n    model = TiledDinoModel(\n        backbone_name=backbone_name,\n        num_tiles=num_tiles,\n        mlp_hidden_dims=mlp_hidden_dims,\n        dropout=dropout,\n        freeze_backbone=True\n    )\n    \n    # Load weights (handle DataParallel if needed)\n    state_dict = checkpoint['model_state_dict']\n    # Remove 'module.' prefix if model was trained with DataParallel\n    if any(k.startswith('module.') for k in state_dict.keys()):\n        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n    \n    model.load_state_dict(state_dict)\n    model.to(device)\n    model.eval()\n    \n    print(f\"âœ“ Model loaded! Best RÂ²: {checkpoint.get('weighted_r2', 'N/A')}\")\n    \n    # Load test data\n    print(f\"\\nðŸ“‚ Loading test data from {DATA_DIR}...\")\n    test_df = load_test_data(DATA_DIR)\n    print(f\"âœ“ Found {len(test_df)} test images\")\n    \n    # Create dataset and dataloader\n    transform = TileTransform(tile_size=TILE_SIZE, include_global=USE_GLOBAL_STREAM)\n    test_dataset = TestDataset(test_df, DATA_DIR, transform)\n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=BATCH_SIZE,\n        shuffle=False,\n        num_workers=NUM_WORKERS,\n        pin_memory=True\n    )\n    \n    # Run inference\n    print(f\"\\nðŸ”® Running inference...\")\n    predictions, image_ids = run_inference(model, test_loader, device)\n    \n    print(f\"âœ“ Generated predictions for {len(predictions)} images\")\n    print(f\"Prediction stats:\")\n    target_names = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n    for i, name in enumerate(target_names):\n        print(f\"  {name}: mean={predictions[:, i].mean():.2f}, \"\n              f\"std={predictions[:, i].std():.2f}, \"\n              f\"min={predictions[:, i].min():.2f}, \"\n              f\"max={predictions[:, i].max():.2f}\")\n    \n    # Create submission\n    print(f\"\\nðŸ’¾ Creating submission file...\")\n    submission_df = create_submission(predictions, image_ids, OUTPUT_PATH)\n    \n    print(f\"âœ“ Submission saved to: {OUTPUT_PATH}\")\n    print(f\"Submission shape: {submission_df.shape}\")\n    print(f\"\\nFirst few rows:\")\n    print(submission_df.head(10))\n    \n    print(f\"\\nðŸŽ‰ DONE! Download {OUTPUT_PATH} and submit to competition!\")\n\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}