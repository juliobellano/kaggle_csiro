{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6d91450",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-22T04:50:06.919518Z",
     "iopub.status.busy": "2025-12-22T04:50:06.919036Z",
     "iopub.status.idle": "2025-12-22T04:50:08.030093Z",
     "shell.execute_reply": "2025-12-22T04:50:08.029394Z"
    },
    "papermill": {
     "duration": 1.116123,
     "end_time": "2025-12-22T04:50:08.032142",
     "exception": false,
     "start_time": "2025-12-22T04:50:06.916019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/csiro-biomass/sample_submission.csv\n",
      "/kaggle/input/csiro-biomass/train.csv\n",
      "/kaggle/input/csiro-biomass/test.csv\n",
      "/kaggle/input/csiro-biomass/test/ID1001187975.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2099464826.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2037861084.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1211362607.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1853508321.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID193102215.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID698608346.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1859251563.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1880764911.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID853954911.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1403107574.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1781353117.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID384648061.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1563418511.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2125100696.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID482555369.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID638711343.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID779628955.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1876271942.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1692894460.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID746335827.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1136169672.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1471216911.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID846154859.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1294770420.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1183807388.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID423506847.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1889150649.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1140993511.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1413758094.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1545077474.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID95050718.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID528010569.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1645161155.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID786365141.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID896386823.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1025234388.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID663006174.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1509266870.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1496750796.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID471758347.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID740402124.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1624268863.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1098771283.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID710341728.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2086966681.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1573329652.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID54128926.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID50027657.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1559189397.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID290369222.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1590632667.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID552040066.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID488873801.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID363069566.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1839139621.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1131079710.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2010625680.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID152157478.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1357758282.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1498398599.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID679913293.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID697718693.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID4464212.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1275072698.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1579942839.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID799079114.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1415329644.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1510574031.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1078930021.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1456861072.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID930534670.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID13162390.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID567744300.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID344618040.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID566966892.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1437386574.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID667059550.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID72895391.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1193692654.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1386202352.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID871463897.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2096636211.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2003438517.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID21377800.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID230058600.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1753847361.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1512751450.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID12390962.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1746343319.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID978026131.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID383231615.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID146920896.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1036339023.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1168534540.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1859792585.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1251029854.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1113329413.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1874904894.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1671844336.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1831254380.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1103883611.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID797502182.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1784585001.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1058383417.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1488408526.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID429799190.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1291116815.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1516374298.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1618597318.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1345375788.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID686797154.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1139866256.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1149598723.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID212206250.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID112966473.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1540480250.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID544444725.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1513184765.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID668330410.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1444674500.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1962379474.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID605134229.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID914754166.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID354528442.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID950496197.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1395011773.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1357768767.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID210865340.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID936984905.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1976436386.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1215977190.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID803479541.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1244346858.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID158170916.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1208644039.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1314135397.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1012260530.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1053972079.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID656251220.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1084819986.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1337107565.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1268934251.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID617132135.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1472525822.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID668475812.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID681680726.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1476045099.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1570190541.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1403078396.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2030696575.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1782608354.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID194823383.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID196516535.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID212206832.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1638922597.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1457700382.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1989506559.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID789169173.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1634731537.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1428837636.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2006686196.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID885388135.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1789853061.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1655778545.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID697059386.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID121331988.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2099742797.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID342818398.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID317990700.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID706288721.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1159071020.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID755710743.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1254829053.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID475010202.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1693880739.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1894998379.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID48303557.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1385921939.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID147528735.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID407646960.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1035947949.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1119761112.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1988033238.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1857489997.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID742198710.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID588120964.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID431471530.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID353424190.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID380752847.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2069766023.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID600602588.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID560946727.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1011485656.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID808079729.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1217108125.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1623964968.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID980878870.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID793526563.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID397994621.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID975115267.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1237349078.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID684383343.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID866684633.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1665142816.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2048645043.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1953171547.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1451025862.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID71885430.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID307060225.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID969218269.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID980538882.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1028611175.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID670276799.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2002797732.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1374789439.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID473494649.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1993907137.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1962197151.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID828217731.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID972274220.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1954669045.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1354190372.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1458758610.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID40849327.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1952813879.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID572336285.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1473228876.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1963715583.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1463690813.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1899025384.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID386216505.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1789265307.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID315357834.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2089023774.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID520514019.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1970522802.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1139918758.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1051144034.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1370004842.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID761508093.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2052993274.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1277756619.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID6269659.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1574125908.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID135365668.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1182523622.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID554314721.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1049634115.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1127246618.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID900012207.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID574213894.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID415656958.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID61833032.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2053315094.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID550623196.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID657448172.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1675365449.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2014192906.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID162394992.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID968643034.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID684062938.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID802547515.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID294150104.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1618145129.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID956512130.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID142751858.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID325799913.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID443091455.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID661372352.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1062837331.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID498304885.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID187238869.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1450399782.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2056023629.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID576621307.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1199150612.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1411613934.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID105271783.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1703304524.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID875119737.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1176292407.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1729002155.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2091439402.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID576137678.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1946311744.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1982662138.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID983582017.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID661817669.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID753699705.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1789834546.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID529933668.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID490139972.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID743847993.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID7850481.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1088965591.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID629980789.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1119739385.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1477176296.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1113121340.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2131261930.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2145635095.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1414371018.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1148666289.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID839432753.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID157479394.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1761544403.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID846984946.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID751517087.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID577112774.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID353997899.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID748979397.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1070112260.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1108283583.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1868719645.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1980675327.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1163061745.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1148528732.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID534966093.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1717006117.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1953218650.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID633775166.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID808093827.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1997244125.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1920959057.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1948354837.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID364856705.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID249042826.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID332742639.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1680597197.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1421714468.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID905397692.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1782509721.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID141370843.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2056982009.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID94564238.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID8209776.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID908524512.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID610397481.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID750820644.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1515990019.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1547945326.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID587125778.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1620371305.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1474775613.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID545360459.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1783499590.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1249094008.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1525817840.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID227847873.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1052620238.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1888700589.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID2052442675.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID963903358.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1121692672.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1343327476.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID1667778338.jpg\n",
      "/kaggle/input/csiro-biomass/train/ID257822026.jpg\n",
      "/kaggle/input/dinov2-1/__results__.html\n",
      "/kaggle/input/dinov2-1/__notebook__.ipynb\n",
      "/kaggle/input/dinov2-1/__output__.json\n",
      "/kaggle/input/dinov2-1/custom.css\n",
      "/kaggle/input/dinov2-1/experiments/dinov2_tiled/fold_1/history.csv\n",
      "/kaggle/input/dinov2-1/experiments/dinov2_tiled/fold_1/best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b8128f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T04:50:08.038684Z",
     "iopub.status.busy": "2025-12-22T04:50:08.038178Z",
     "iopub.status.idle": "2025-12-22T04:50:39.575015Z",
     "shell.execute_reply": "2025-12-22T04:50:39.573381Z"
    },
    "papermill": {
     "duration": 31.542149,
     "end_time": "2025-12-22T04:50:39.577280",
     "exception": false,
     "start_time": "2025-12-22T04:50:08.035131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üåø DINOv2 Tiled Model - Inference\n",
      "================================================================================\n",
      "Device: cuda\n",
      "GPU: Tesla T4\n",
      "‚úì Found CSIRO dataset at: /kaggle/input/csiro-biomass\n",
      "Data: /kaggle/input/csiro-biomass\n",
      "\n",
      "üìÇ Loading test data...\n",
      "‚úì Test images: 1\n",
      "\n",
      "üîÆ Running inference...\n",
      "Loading model from: /kaggle/input/dinov2-1/experiments/dinov2_tiled/fold_1/best_model.pth\n",
      "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is not available (SwiGLU)\")\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n",
      "  warnings.warn(\"xFormers is not available (Attention)\")\n",
      "/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n",
      "  warnings.warn(\"xFormers is not available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vitl14/dinov2_vitl14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vitl14_pretrain.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.13G/1.13G [00:03<00:00, 314MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Model loaded successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:02<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying physical constraint (blend=0.3)...\n",
      "\n",
      "üìù Creating submission...\n",
      "\n",
      "‚úì Submission saved to: /kaggle/working/submission.csv\n",
      "  Shape: (5, 2)\n",
      "  Sample rows:\n",
      "                    sample_id     target\n",
      "0   ID1001187975__Dry_Green_g  38.291405\n",
      "1    ID1001187975__Dry_Dead_g  16.978737\n",
      "2  ID1001187975__Dry_Clover_g   2.906584\n",
      "3         ID1001187975__GDM_g  41.287861\n",
      "4   ID1001187975__Dry_Total_g  58.096733\n",
      "\n",
      "üìä Prediction Summary:\n",
      "  Dry_Green_g    : mean= 38.29, std=  0.00, min= 38.29, max= 38.29\n",
      "  Dry_Dead_g     : mean= 16.98, std=  0.00, min= 16.98, max= 16.98\n",
      "  Dry_Clover_g   : mean=  2.91, std=  0.00, min=  2.91, max=  2.91\n",
      "  GDM_g          : mean= 41.29, std=  0.00, min= 41.29, max= 41.29\n",
      "  Dry_Total_g    : mean= 58.10, std=  0.00, min= 58.10, max= 58.10\n",
      "\n",
      "================================================================================\n",
      "‚úÖ INFERENCE COMPLETE\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DINOv2 Tiled Inference for Kaggle\n",
    "==================================================\n",
    "\n",
    "Copy this entire file into a single Kaggle notebook cell and run.\n",
    "\n",
    "Prerequisites:\n",
    "1. Enable GPU in Kaggle\n",
    "2. Enable Internet (for DINOv2 download if needed)\n",
    "3. Have CSIRO dataset in /kaggle/input/\n",
    "4. Have trained model checkpoint accessible\n",
    "\n",
    "Usage:\n",
    "- Set CHECKPOINT_PATH to your trained model\n",
    "- Run the cell\n",
    "- Submission will be saved to /kaggle/working/submission.csv\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "class InferenceConfig:\n",
    "    \"\"\"Inference configuration.\"\"\"\n",
    "    # Paths - Auto-detect or specify\n",
    "    DATA_DIR = None  # Will be auto-detected\n",
    "    CHECKPOINT_PATH = '/kaggle/input/dinov2-1/experiments/dinov2_tiled/fold_1/best_model.pth'  # UPDATE THIS\n",
    "    OUTPUT_PATH = '/kaggle/working/submission.csv'\n",
    "    \n",
    "    # Model settings (should match training)\n",
    "    BACKBONE = 'dinov2_vitl14'\n",
    "    USE_GLOBAL_STREAM = True\n",
    "    TILE_SIZE = 518\n",
    "    MLP_HIDDEN_DIMS = [1024, 512]\n",
    "    DROPOUT = 0.3\n",
    "    \n",
    "    # Inference settings\n",
    "    BATCH_SIZE = 8\n",
    "    NUM_WORKERS = 4\n",
    "    USE_TTA = False  # Test-Time Augmentation (slower but better)\n",
    "    APPLY_CONSTRAINT = True  # Post-processing\n",
    "    CONSTRAINT_BLEND = 0.3  # How much to blend (0=off, 1=full)\n",
    "    \n",
    "    # Ensemble (if you have multiple fold models)\n",
    "    USE_ENSEMBLE = False\n",
    "    ENSEMBLE_CHECKPOINTS = [\n",
    "        # '/kaggle/input/your-model/fold_0/best_model.pth',\n",
    "        # '/kaggle/input/your-model/fold_1/best_model.pth',\n",
    "        # Add more checkpoint paths here\n",
    "    ]\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DATA TRANSFORMS\n",
    "# =============================================================================\n",
    "\n",
    "class TileTransform:\n",
    "    \"\"\"Split image into 2x2 tiles + optional global.\"\"\"\n",
    "    \n",
    "    def __init__(self, tile_size=518, include_global=True):\n",
    "        self.tile_size = tile_size\n",
    "        self.include_global = include_global\n",
    "        \n",
    "        self.normalize = T.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "        self.resize = T.Resize((tile_size, tile_size), interpolation=T.InterpolationMode.BICUBIC, antialias=True)\n",
    "    \n",
    "    def _crop_tile(self, image, tile_idx):\n",
    "        w, h = image.size\n",
    "        half_w, half_h = w // 2, h // 2\n",
    "        positions = {\n",
    "            0: (0, 0, half_w, half_h),\n",
    "            1: (half_w, 0, w, half_h),\n",
    "            2: (0, half_h, half_w, h),\n",
    "            3: (half_w, half_h, w, h),\n",
    "        }\n",
    "        return image.crop(positions[tile_idx])\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        tiles = []\n",
    "        for i in range(4):\n",
    "            tile = self._crop_tile(image, i)\n",
    "            tile = self.resize(tile)\n",
    "            tile = T.ToTensor()(tile)\n",
    "            tile = self.normalize(tile)\n",
    "            tiles.append(tile)\n",
    "        \n",
    "        if self.include_global:\n",
    "            global_img = self.resize(image)\n",
    "            global_img = T.ToTensor()(global_img)\n",
    "            global_img = self.normalize(global_img)\n",
    "            tiles.append(global_img)\n",
    "        \n",
    "        return torch.stack(tiles, dim=0)\n",
    "\n",
    "\n",
    "class TTATransform:\n",
    "    \"\"\"Test-Time Augmentation wrapper.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_transform, tta_func):\n",
    "        self.base_transform = base_transform\n",
    "        self.tta_func = tta_func\n",
    "    \n",
    "    def __call__(self, image):\n",
    "        augmented = self.tta_func(image)\n",
    "        return self.base_transform(augmented)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# DATASET\n",
    "# =============================================================================\n",
    "\n",
    "class PastureTestDataset(Dataset):\n",
    "    \"\"\"Test dataset for pasture images.\"\"\"\n",
    "    \n",
    "    def __init__(self, df, data_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = self.data_dir / row['image_path']\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            tiles = self.transform(image)\n",
    "        else:\n",
    "            tiles = torch.zeros(5, 3, 518, 518)\n",
    "        \n",
    "        # Return dummy targets for consistency\n",
    "        targets = torch.zeros(5, dtype=torch.float32)\n",
    "        return tiles, targets\n",
    "\n",
    "\n",
    "def load_test_data(data_dir):\n",
    "    \"\"\"Load test data.\"\"\"\n",
    "    test_df = pd.read_csv(Path(data_dir) / 'test.csv')\n",
    "    \n",
    "    # Extract image_id from sample_id\n",
    "    test_df['image_id'] = test_df['sample_id'].str.split('__').str[0]\n",
    "    \n",
    "    # Get unique images with paths\n",
    "    unique_images = test_df.groupby('image_id').first().reset_index()[['image_id', 'image_path']]\n",
    "    \n",
    "    return unique_images\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MODEL\n",
    "# =============================================================================\n",
    "\n",
    "class TiledDinoModel(nn.Module):\n",
    "    \"\"\"DINOv2 with tiled input processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, backbone_name='dinov2_vitl14', num_tiles=5, \n",
    "                 mlp_hidden_dims=[1024, 512], dropout=0.3, freeze_backbone=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = torch.hub.load('facebookresearch/dinov2', backbone_name, pretrained=True)\n",
    "        self.feature_dim = self.backbone.embed_dim\n",
    "        self.num_tiles = num_tiles\n",
    "        \n",
    "        if freeze_backbone:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # MLP head\n",
    "        layers = []\n",
    "        prev_dim = num_tiles * self.feature_dim\n",
    "        for hidden_dim in mlp_hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(p=dropout),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        layers.append(nn.Linear(prev_dim, 5))\n",
    "        self.head = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, tiles):\n",
    "        batch_size, num_tiles, channels, height, width = tiles.shape\n",
    "        tiles_flat = tiles.reshape(batch_size * num_tiles, channels, height, width)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = self.backbone(tiles_flat)\n",
    "        \n",
    "        features = features.contiguous().view(batch_size, num_tiles * self.feature_dim)\n",
    "        return self.head(features)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# INFERENCE FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def load_model(checkpoint_path, config, device):\n",
    "    \"\"\"Load trained model from checkpoint.\"\"\"\n",
    "    print(f\"Loading model from: {checkpoint_path}\")\n",
    "    \n",
    "    num_tiles = 5 if config.USE_GLOBAL_STREAM else 4\n",
    "    \n",
    "    model = TiledDinoModel(\n",
    "        backbone_name=config.BACKBONE,\n",
    "        num_tiles=num_tiles,\n",
    "        mlp_hidden_dims=config.MLP_HIDDEN_DIMS,\n",
    "        dropout=config.DROPOUT,\n",
    "        freeze_backbone=True\n",
    "    )\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=True)\n",
    "    \n",
    "    # Handle different checkpoint formats\n",
    "    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"‚úì Model loaded successfully\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict_single(model, dataloader, device):\n",
    "    \"\"\"Run inference with a single model.\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for tiles, _ in tqdm(dataloader, desc='Inference'):\n",
    "            tiles = tiles.to(device)\n",
    "            outputs = model(tiles)\n",
    "            predictions.append(outputs.cpu().numpy())\n",
    "    \n",
    "    return np.vstack(predictions)\n",
    "\n",
    "\n",
    "def predict_with_tta(model, dataset, device, batch_size, num_workers):\n",
    "    \"\"\"Run inference with Test-Time Augmentation.\"\"\"\n",
    "    print(\"Running TTA (4 augmentations)...\")\n",
    "    \n",
    "    base_transform = dataset.transform\n",
    "    \n",
    "    # Define TTA augmentations\n",
    "    tta_funcs = [\n",
    "        lambda img: img,  # Original\n",
    "        lambda img: TF.hflip(img),  # Horizontal flip\n",
    "        lambda img: TF.vflip(img),  # Vertical flip\n",
    "        lambda img: TF.vflip(TF.hflip(img)),  # Both flips\n",
    "    ]\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    for tta_idx, tta_func in enumerate(tta_funcs):\n",
    "        print(f\"  TTA {tta_idx + 1}/{len(tta_funcs)}...\")\n",
    "        \n",
    "        # Update transform\n",
    "        dataset.transform = TTATransform(base_transform, tta_func)\n",
    "        \n",
    "        # Create dataloader\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Run inference\n",
    "        predictions = predict_single(model, dataloader, device)\n",
    "        all_predictions.append(predictions)\n",
    "    \n",
    "    # Restore original transform\n",
    "    dataset.transform = base_transform\n",
    "    \n",
    "    # Average predictions\n",
    "    return np.mean(all_predictions, axis=0)\n",
    "\n",
    "\n",
    "def ensemble_predict(models, dataloader, device):\n",
    "    \"\"\"Ensemble predictions from multiple models.\"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"Model {i + 1}/{len(models)}...\")\n",
    "        predictions = predict_single(model, dataloader, device)\n",
    "        all_predictions.append(predictions)\n",
    "    \n",
    "    return np.mean(all_predictions, axis=0)\n",
    "\n",
    "\n",
    "def apply_constraint(predictions, blend=0.3):\n",
    "    \"\"\"Apply physical constraint post-processing.\"\"\"\n",
    "    predictions = predictions.copy()\n",
    "    \n",
    "    # Extract components\n",
    "    green = predictions[:, 0]\n",
    "    dead = predictions[:, 1]\n",
    "    clover = predictions[:, 2]\n",
    "    total = predictions[:, 4]\n",
    "    \n",
    "    # Compute component sum\n",
    "    component_sum = green + dead + clover\n",
    "    \n",
    "    # Blend with original total\n",
    "    adjusted_total = (1 - blend) * total + blend * component_sum\n",
    "    \n",
    "    # Update predictions\n",
    "    predictions[:, 4] = adjusted_total\n",
    "    \n",
    "    # Ensure non-negative\n",
    "    predictions = np.maximum(predictions, 0)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def create_submission(predictions, test_df, output_path):\n",
    "    \"\"\"Create submission CSV.\"\"\"\n",
    "    target_names = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "    \n",
    "    rows = []\n",
    "    for i, row in test_df.iterrows():\n",
    "        image_id = row['image_id']\n",
    "        for j, target_name in enumerate(target_names):\n",
    "            sample_id = f\"{image_id}__{target_name}\"\n",
    "            target_value = predictions[i, j]\n",
    "            rows.append({\n",
    "                'sample_id': sample_id,\n",
    "                'target': target_value\n",
    "            })\n",
    "    \n",
    "    submission_df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    submission_df.to_csv(output_path, index=False)\n",
    "    \n",
    "    print(f\"\\n‚úì Submission saved to: {output_path}\")\n",
    "    print(f\"  Shape: {submission_df.shape}\")\n",
    "    print(f\"  Sample rows:\")\n",
    "    print(submission_df.head(10))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# AUTO-DETECT PATHS\n",
    "# =============================================================================\n",
    "\n",
    "def find_csiro_data_dir():\n",
    "    \"\"\"Find CSIRO dataset in Kaggle input.\"\"\"\n",
    "    kaggle_input = Path('/kaggle/input')\n",
    "    \n",
    "    if not kaggle_input.exists():\n",
    "        return '../csiro-biomass'\n",
    "    \n",
    "    for dirname, _, filenames in os.walk(kaggle_input):\n",
    "        if 'test.csv' in filenames:\n",
    "            print(f\"‚úì Found CSIRO dataset at: {dirname}\")\n",
    "            return dirname\n",
    "    \n",
    "    raise FileNotFoundError(\"Could not find CSIRO dataset in /kaggle/input\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN\n",
    "# =============================================================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main inference function.\"\"\"\n",
    "    config = InferenceConfig()\n",
    "    \n",
    "    # Get device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üåø DINOv2 Tiled Model - Inference\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    # Find data directory\n",
    "    if config.DATA_DIR is None:\n",
    "        config.DATA_DIR = find_csiro_data_dir()\n",
    "    print(f\"Data: {config.DATA_DIR}\")\n",
    "    \n",
    "    # Load test data\n",
    "    print(\"\\nüìÇ Loading test data...\")\n",
    "    test_df = load_test_data(config.DATA_DIR)\n",
    "    print(f\"‚úì Test images: {len(test_df)}\")\n",
    "    \n",
    "    # Create dataset\n",
    "    transform = TileTransform(config.TILE_SIZE, config.USE_GLOBAL_STREAM)\n",
    "    test_dataset = PastureTestDataset(test_df, config.DATA_DIR, transform)\n",
    "    \n",
    "    # Create dataloader\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=config.NUM_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Run inference\n",
    "    print(f\"\\nüîÆ Running inference...\")\n",
    "    \n",
    "    if config.USE_ENSEMBLE and len(config.ENSEMBLE_CHECKPOINTS) > 1:\n",
    "        print(f\"Ensemble mode: {len(config.ENSEMBLE_CHECKPOINTS)} models\")\n",
    "        models = []\n",
    "        for ckpt_path in config.ENSEMBLE_CHECKPOINTS:\n",
    "            model = load_model(ckpt_path, config, device)\n",
    "            models.append(model)\n",
    "        \n",
    "        predictions = ensemble_predict(models, test_loader, device)\n",
    "    else:\n",
    "        # Single model inference\n",
    "        model = load_model(config.CHECKPOINT_PATH, config, device)\n",
    "        \n",
    "        if config.USE_TTA:\n",
    "            predictions = predict_with_tta(\n",
    "                model, test_dataset, device, \n",
    "                config.BATCH_SIZE, config.NUM_WORKERS\n",
    "            )\n",
    "        else:\n",
    "            predictions = predict_single(model, test_loader, device)\n",
    "    \n",
    "    # Apply constraint post-processing\n",
    "    if config.APPLY_CONSTRAINT:\n",
    "        print(f\"Applying physical constraint (blend={config.CONSTRAINT_BLEND})...\")\n",
    "        predictions = apply_constraint(predictions, config.CONSTRAINT_BLEND)\n",
    "    \n",
    "    # Create submission\n",
    "    print(\"\\nüìù Creating submission...\")\n",
    "    create_submission(predictions, test_df, config.OUTPUT_PATH)\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nüìä Prediction Summary:\")\n",
    "    target_names = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "    for i, name in enumerate(target_names):\n",
    "        print(f\"  {name:15s}: mean={predictions[:, i].mean():6.2f}, \"\n",
    "              f\"std={predictions[:, i].std():6.2f}, \"\n",
    "              f\"min={predictions[:, i].min():6.2f}, \"\n",
    "              f\"max={predictions[:, i].max():6.2f}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"‚úÖ INFERENCE COMPLETE\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RUN\n",
    "# =============================================================================\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "isSourceIdPinned": false,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "sourceId": 287724086,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.987953,
   "end_time": "2025-12-22T04:50:42.525063",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-22T04:50:04.537110",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
